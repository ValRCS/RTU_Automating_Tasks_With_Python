{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda7b8f0",
   "metadata": {},
   "source": [
    "# Topic 7 — Web Automation with Selenium\n",
    "\n",
    "## 1. Goals of This Notebook\n",
    "In this notebook you will learn:\n",
    "- **Why Selenium exists** and when it is needed for scraping or automation.  \n",
    "  Selenium controls a real browser and can render dynamic JavaScript-based content that normal `requests` cannot retrieve.\n",
    "- **How to install and configure Selenium on Windows**, including notes on drivers, PATH issues, and running inside Jupyter.\n",
    "- **How to create browser sessions**, navigate, extract data, wait for elements, click buttons, scroll pages, and automate tasks.\n",
    "- **A full scraping example** using a safe demo website.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Comparison With Requests + BeautifulSoup (Video 6 Recap)\n",
    "\n",
    "### When Requests + BS4 *is enough*:\n",
    "- Static HTML pages  \n",
    "- Simple extraction  \n",
    "- No interactions  \n",
    "- No JavaScript rendering  \n",
    "- Very fast and lightweight  \n",
    "\n",
    "### When Requests + BS4 *fails*:\n",
    "- Page loads content **only after JavaScript runs**\n",
    "- Websites with pagination that loads dynamically\n",
    "- Login-required sites with CSRF tokens\n",
    "- Infinite scrolling / lazy loading\n",
    "\n",
    "### Why Selenium:\n",
    "- Executes JavaScript  \n",
    "- Can click, type, scroll, and interact like a real user  \n",
    "- Good for:\n",
    "  - dynamic sites  \n",
    "  - testing workflows  \n",
    "  - scraping where no clean API exists  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Installing Selenium on Windows\n",
    "\n",
    "### Step 1 — Install Selenium Python package\n",
    "Run in terminal or inside Jupyter:\n",
    "\n",
    "```\n",
    "pip install selenium\n",
    "```\n",
    "\n",
    "### Step 2 — Browser Driver (Modern Approach: Selenium Manager)\n",
    "As of Selenium 4.10+, Selenium **automatically** downloads the correct browser driver for:\n",
    "- Chrome  \n",
    "- Edge  \n",
    "- Firefox  \n",
    "\n",
    "**No need to separately download chromedriver.exe.**\n",
    "\n",
    "### Step 3 — Common Windows Pitfalls\n",
    "- **PATH issues**: older Selenium tutorials require manual driver installation — ignore those.\n",
    "- **Antivirus blocking**: some AV tools block automated browser control.  \n",
    "- **Browser version mismatch**: Selenium Manager eliminates this problem.\n",
    "- **Running inside Jupyter**:\n",
    "  - Jupyter blocks some interactive window features  \n",
    "  - Browser will launch in a new system window  \n",
    "\n",
    "### Step 4 — Verify Installation\n",
    "We’ll run a minimal script below.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Choosing a Practice Website\n",
    "\n",
    "We will use:\n",
    "\n",
    "### **Quotes to Scrape (JavaScript version)**  \n",
    "https://quotes.toscrape.com/js\n",
    "\n",
    "It requires JavaScript, so standard requests fail — perfect for Selenium demos.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Selenium Basics\n",
    "\n",
    "### 5.1 Creating a Browser Instance\n",
    "We use Chrome by default. Selenium will handle driver installation.\n",
    "\n",
    "### 5.2 Opening a Page\n",
    "We navigate using `.get(url)`.\n",
    "\n",
    "### 5.3 Locating Elements\n",
    "Use:\n",
    "- `By.CSS_SELECTOR`  \n",
    "- `By.XPATH`  \n",
    "- `By.CLASS_NAME`  \n",
    "- `By.TAG_NAME`\n",
    "\n",
    "### 5.4 Extracting Content\n",
    "Every Selenium element supports:\n",
    "- `.text`  \n",
    "- `.get_attribute(\"href\")`  \n",
    "\n",
    "### 5.5 Waiting for Dynamic Content\n",
    "Use:  \n",
    "`WebDriverWait(driver, timeout).until(condition)`\n",
    "\n",
    "### 5.6 Interactions\n",
    "Selenium supports:\n",
    "- `.click()`  \n",
    "- `.send_keys()`  \n",
    "- `.execute_script()` for scrolling\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830fbcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Minimal test script — open python.org\n",
    "driver = webdriver.Chrome()  # Selenium Manager auto-installs driver\n",
    "\n",
    "driver.get(\"https://www.python.org\")\n",
    "\n",
    "print(\"Title:\", driver.title)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b68c547",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Practical Selenium Demonstration: Scraping Quotes\n",
    "\n",
    "We target **https://quotes.toscrape.com/js**  \n",
    "This version loads quotes via JavaScript and requires Selenium.\n",
    "\n",
    "Process:\n",
    "1. Open page  \n",
    "2. Wait for quotes to load  \n",
    "3. Extract quote text + author  \n",
    "4. Click “Next”  \n",
    "5. Repeat for 3 pages  \n",
    "6. Save results to CSV  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://quotes.toscrape.com/js\")\n",
    "\n",
    "all_quotes = []\n",
    "\n",
    "for page in range(3):  # scrape first 3 pages\n",
    "    print(f\"Scraping page {page+1}\")\n",
    "\n",
    "    # Wait for quote elements\n",
    "    quotes = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, \"quote\"))\n",
    "    )\n",
    "\n",
    "    for q in quotes:\n",
    "        text = q.find_element(By.CLASS_NAME, \"text\").text\n",
    "        author = q.find_element(By.CLASS_NAME, \"author\").text\n",
    "        all_quotes.append([text, author])\n",
    "\n",
    "    # Try clicking the next button if exists\n",
    "    try:\n",
    "        next_btn = driver.find_element(By.CSS_SELECTOR, \"li.next > a\")\n",
    "        next_btn.click()\n",
    "    except:\n",
    "        print(\"No next page.\")\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save results\n",
    "with open(\"quotes_output.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"quote\", \"author\"])\n",
    "    writer.writerows(all_quotes)\n",
    "\n",
    "all_quotes[:5]  # show sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf1dfa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Scrolling & Screenshot Example\n",
    "\n",
    "Useful for:\n",
    "- Infinite scroll pages\n",
    "- Triggering lazy-loaded content\n",
    "- Capturing evidence of state\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4fc7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://quotes.toscrape.com/js\")\n",
    "\n",
    "# Scroll to bottom\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.save_screenshot(\"selenium_screenshot.png\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3a257",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Cleanup, Tips & Future Work\n",
    "\n",
    "- Selenium is slower than Requests/BS4 — use only when necessary.  \n",
    "- Combine both approaches:\n",
    "  - Selenium to log in / load dynamic HTML  \n",
    "  - Requests to fetch data behind authenticated session  \n",
    "- For production, run Selenium in:\n",
    "  - **Headless mode**\n",
    "  - **Docker containers**\n",
    "  - **Selenium Grid** for parallel browsing  \n",
    "\n",
    "End of Notebook.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
